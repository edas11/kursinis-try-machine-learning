{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from density_db import density_database\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from tensorflow import keras\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "def get_data():\n",
    "    rawData = density_database('density.db').selectAllErrorsWithParams('Redfield').fetchall()\n",
    "    return pd.DataFrame(data=rawData, columns=['delta_e', 'J', 'lambda', 'gamma', 'T', 'error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "def plot_error(data):\n",
    "    data.loc[\n",
    "        (data['delta_e'] == 100.)\n",
    "        & (data['J'] == 100.)\n",
    "        & (data['lambda'] == 100.)\n",
    "        & (data['gamma'] == 100.)\n",
    "        & (data['T'] == 300.)\n",
    "    ].plot(kind=\"scatter\", x=\"delta_e\", y=\"error\", logy=True)\n",
    "    plt.ylim(10**-4,10**-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore combinations\n",
    "def correletions():\n",
    "    tryData = data.copy()\n",
    "    tryData['gamma-lambda'] = tryData['gamma']*tryData['lambda']\n",
    "    tryData['gamma-delta_e'] = tryData['gamma']*tryData['delta_e']\n",
    "    tryData['gamma-J'] = tryData['gamma']*tryData['J']\n",
    "    tryData['lambda-delta_e'] = tryData['lambda']*tryData['delta_e']\n",
    "    tryData['lambda-J'] = tryData['lambda']*tryData['J']\n",
    "    tryData['delta_e-J'] = tryData['delta_e']*tryData['J']\n",
    "    corr_matrix = tryData.corr()\n",
    "    corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_and_test_sets(data):\n",
    "    modifiedData = data.copy()\n",
    "    modifiedData['gamma-lambda'] = data['gamma']*data['lambda']\n",
    "    modifiedData['gamma-delta_e'] = data['gamma']*data['delta_e']\n",
    "    modifiedData['gamma-J'] = data['gamma']*data['J']\n",
    "    modifiedData['lambda-delta_e'] = data['lambda']*data['delta_e']\n",
    "    modifiedData['lambda-J'] = data['lambda']*data['J']\n",
    "    modifiedData['delta_e-J'] = data['delta_e']*data['J']\n",
    "    #return train_test_split(modifiedData, test_size=0.2, random_state=42)\n",
    "    return modifiedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = prepare_train_and_test_sets(get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mspe(y, y_predicted):\n",
    "    return 100 * np.sum(np.square((y - y_predicted)/y)) / len(y)\n",
    "\n",
    "def mape(y, y_predicted):\n",
    "    return 100 * np.sum(np.abs((y - y_predicted)/y)) / len(y)\n",
    " \n",
    "def trainMethod(method, train_set, pipeline = None):\n",
    "    data_labels = np.array(train_set[\"error\"].copy())\n",
    "    data_prepared = np.array(train_set.drop(\"error\", axis=1))\n",
    "    if pipeline:\n",
    "        data_prepared = pipeline.fit_transform(data_prepared)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=47)\n",
    "    errors = [];\n",
    "    for train, test in kfold.split(data_prepared, data_labels):\n",
    "        method.fit(data_prepared[train], data_labels[train])\n",
    "        labels_predicted = method.predict(data_prepared[test])\n",
    "        errors.append(mape(data_labels[test], labels_predicted))\n",
    "    print('Error: %f' % (sum(errors)/len(errors)))\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNueralNetwork(train_set):\n",
    "    train_set_nn = train_set.copy()\n",
    "    pipeline = Pipeline([\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "    data_labels = np.array(train_set_nn[\"error\"].copy())\n",
    "    data_prepared = np.array(pipeline.fit_transform(train_set_nn.drop(\"error\", axis=1)))\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=47)\n",
    "    errors = [];\n",
    "    for train, test in kfold.split(data_prepared, data_labels):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(11, activation='softmax', input_shape=(11,)),\n",
    "            keras.layers.Dense(11, activation='softmax'),\n",
    "            keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='Adam', loss='mean_absolute_percentage_error')\n",
    "        model.fit(data_prepared[train], data_labels[train], epochs=200, validation_split=0, verbose=0)\n",
    "        labels_predicted = model.predict(data_prepared[test])\n",
    "        errors.append(mape(data_labels[test], labels_predicted[:,0]))\n",
    "        #print(errors)\n",
    "        #break\n",
    "    print('Error: %f' % (sum(errors)/len(errors)))\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear su validation\n",
    "def linear():\n",
    "    lin_reg = LinearRegression()\n",
    "    trainMethod(lin_reg, train_set)\n",
    "    \n",
    "#forest su validation\n",
    "def randomForestRegressor():\n",
    "    for_reg = RandomForestRegressor(n_estimators=100)\n",
    "    trainMethod(for_reg, train_set)\n",
    "    \n",
    "#support vector machines\n",
    "def support_vector_machines():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    svr = LinearSVR()\n",
    "    pipeline = Pipeline([\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "    trainMethod(svr, train_set, pipeline)\n",
    "    warnings.filterwarnings('always')\n",
    "    \n",
    "#k nearest\n",
    "def k_nearest():\n",
    "    eigh = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "    trainMethod(eigh, train_set)\n",
    "    \n",
    "#linear lasso\n",
    "def linear_lasso():\n",
    "    lasso = Lasso()\n",
    "    trainMethod(lasso, train_set)\n",
    "\n",
    "#linear ridge\n",
    "def linear_ridge():\n",
    "    ridge = Ridge()\n",
    "    trainMethod(ridge, train_set)\n",
    "\n",
    "#decision tree\n",
    "def decision_tree():\n",
    "    decision = DecisionTreeRegressor()\n",
    "    trainMethod(decision, train_set)\n",
    "    \n",
    "#gaussian process\n",
    "def gaussian_process():\n",
    "    kernel = DotProduct() + WhiteKernel()\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,random_state=0)\n",
    "    trainMethod(gpr, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "Error: 79.366896\n",
      "\n",
      "linear_lasso\n",
      "Error: 80.752652\n",
      "\n",
      "linear_ridge\n",
      "Error: 79.366874\n",
      "\n",
      "randomForestRegressor\n",
      "Error: 22.981270\n",
      "\n",
      "decision_tree\n",
      "Error: 26.896598\n",
      "\n",
      "k_nearest\n",
      "Error: 20.915795\n",
      "\n",
      "svm\n",
      "Error: 79.793290\n",
      "\n",
      "gaussian_process\n",
      "Error: 78.169086\n",
      "\n",
      "neural network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edvardas/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py:364: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  if isinstance(inputs, collections.Sequence):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 21.093743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14.927877234494682,\n",
       " 34.045571475213556,\n",
       " 65.57720465886582,\n",
       " 11.318383518321436,\n",
       " 11.188185300287293,\n",
       " 11.066417363493642,\n",
       " 8.570994930615852,\n",
       " 19.806670096303147,\n",
       " 12.282645459132,\n",
       " 22.153481464546584]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('linear')\n",
    "linear()\n",
    "print()\n",
    "print('linear_lasso')\n",
    "linear_lasso()\n",
    "print()\n",
    "print('linear_ridge')\n",
    "linear_ridge()\n",
    "print()\n",
    "print('randomForestRegressor')\n",
    "randomForestRegressor()\n",
    "print()\n",
    "print('decision_tree')\n",
    "decision_tree()\n",
    "print()\n",
    "print('k_nearest')\n",
    "k_nearest()\n",
    "print()\n",
    "print('svm')\n",
    "support_vector_machines()\n",
    "print()\n",
    "print('gaussian_process')\n",
    "gaussian_process()\n",
    "print()\n",
    "print('neural network')\n",
    "trainNueralNetwork(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
